{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3618fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit import rdBase\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import re\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "from scoring_functions import get_scoring_function\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33258bd1",
   "metadata": {},
   "source": [
    "# data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b39286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_halogen(string):\n",
    "    \"\"\"Regex to replace Br and Cl with single letters\"\"\"\n",
    "    br = re.compile('Br')\n",
    "    cl = re.compile('Cl')\n",
    "    string = br.sub('R', string)\n",
    "    string = cl.sub('L', string)\n",
    "\n",
    "    return string\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self,file,max_len=140):\n",
    "        self.file = file\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size,self.vocab,self.reversed_vocab = self.get_voc(file)\n",
    "        self.reversed_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def get_voc(self,file):\n",
    "        with open(file, 'r') as f:\n",
    "            chars = f.read().split()\n",
    "        chars +=  ['EOS', 'GO']\n",
    "        chars.sort()\n",
    "        vocab_size = len(chars)\n",
    "        vocab = dict(zip(chars, range(len(chars))))\n",
    "        reversed_vocab = {v: k for k, v in vocab.items()}\n",
    "        return vocab_size,vocab,reversed_vocab\n",
    "        \n",
    "    def tokenize(self, smiles):\n",
    "        \"\"\"Takes a SMILES and return a list of characters/tokens\"\"\"\n",
    "        regex = '(\\[[^\\[\\]]{1,6}\\])'\n",
    "        smiles = replace_halogen(smiles)\n",
    "        char_list = re.split(regex, smiles)\n",
    "        tokenized = []\n",
    "        for char in char_list:\n",
    "            if char.startswith('['):\n",
    "                tokenized.append(char)\n",
    "            else:\n",
    "                chars = [unit for unit in char]\n",
    "                [tokenized.append(unit) for unit in chars]\n",
    "        tokenized.append('EOS')\n",
    "        return tokenized\n",
    "    \n",
    "    def encode(self,char_list):\n",
    "        smiles_matrix = np.zeros(len(char_list), dtype=np.float32)\n",
    "        for i, char in enumerate(char_list):\n",
    "            smiles_matrix[i] = self.vocab[char]\n",
    "        return smiles_matrix\n",
    "    \n",
    "    def decode(self,matrix):\n",
    "        chars = []\n",
    "        for i in matrix:\n",
    "            if i == self.vocab['EOS']: break\n",
    "            chars.append(self.reversed_vocab[i.item()])\n",
    "        smiles = \"\".join(chars)\n",
    "        smiles = smiles.replace(\"L\", \"Cl\").replace(\"R\", \"Br\")\n",
    "        return smiles\n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.chars)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Vocabulary containing {} tokens: {}\".format(len(self), self.chars)\n",
    "    \n",
    "class MolData(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset that takes a file containing SMILES.\n",
    "\n",
    "        Args:\n",
    "                fname : path to a file containing \\n separated SMILES.\n",
    "                voc   : a Vocabulary instance\n",
    "\n",
    "        Returns:\n",
    "                A custom PyTorch dataset for training the Prior.\n",
    "    \"\"\"\n",
    "    def __init__(self, fname, voc):\n",
    "        self.voc = voc\n",
    "        self.smiles = []\n",
    "        with open(fname, 'r') as f:\n",
    "            for line in f:\n",
    "                self.smiles.append(line.split()[0])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        mol = self.smiles[i]\n",
    "        tokenized = self.voc.tokenize(mol)\n",
    "        encoded = self.voc.encode(tokenized)\n",
    "        return encoded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Dataset containing {} structures.\".format(len(self))\n",
    "\n",
    "    @classmethod\n",
    "    def collate_fn(cls, arr):\n",
    "        \"\"\"Function to take a list of encoded sequences and turn them into a batch\"\"\"\n",
    "        max_length = max([seq.size for seq in arr])\n",
    "        collated_arr = np.zeros((len(arr), max_length))\n",
    "        for i, seq in enumerate(arr):\n",
    "            collated_arr[i, :seq.size] = seq\n",
    "        return torch.from_numpy(collated_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76624a",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7117cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRULayer(nn.Module):\n",
    "    def __init__(self, voc_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(voc_size,128)\n",
    "        self.gru1 = nn.GRUCell(128,512)\n",
    "        self.gru2 = nn.GRUCell(512,512)\n",
    "        self.gru3 = nn.GRUCell(512,512)\n",
    "        self.fcn = nn.Linear(512,voc_size)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        x = x.to(device)\n",
    "        h = h.to(device)\n",
    "        h_out = torch.zeros(h.shape).to(device)\n",
    "        x = self.embedding(x).to(device)\n",
    "        x = h_out[0] = self.gru1(x,h[0])\n",
    "        x = h_out[1] = self.gru2(x,h[1])\n",
    "        x = h_out[2] = self.gru3(x,h[2])\n",
    "        x = self.fcn(x)\n",
    "        return x,h_out\n",
    "\n",
    "class RNN():\n",
    "    def __init__(self,voc,batch_size,max_len=140):\n",
    "        global device\n",
    "        self.rnn = GRULayer(voc.vocab_size).to(device)\n",
    "        self.voc = voc\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.loss_fn = nn.BCELoss(reduction='none')\n",
    "    \n",
    "    def bce_loss(self,prob,target):\n",
    "        onehot_target = torch.zeros(prob.shape).to(device)\n",
    "        onehot_target.scatter_(1, target.contiguous().view(-1, 1).data, 1.0)\n",
    "        onehot_target = onehot_target.to(device)\n",
    "#         print(prob,onehot_target)\n",
    "        return self.loss_fn(prob,onehot_target)\n",
    "    \n",
    "    def forward(self,target):\n",
    "#         self.rnn.train()\n",
    "#         target = target.to(device)\n",
    "#         batch_size, seq_length = target.size()\n",
    "#         start_token = Variable(torch.zeros(batch_size, 1).long())\n",
    "#         start_token[:] = self.voc.vocab['GO']\n",
    "#         x = torch.cat((start_token, target[:, :-1]), 1)\n",
    "#         h = torch.zeros(3, self.batch_size, 512).float()\n",
    "\n",
    "#         log_probs = Variable(torch.zeros(batch_size))\n",
    "#         loss = 0\n",
    "#         outs = []\n",
    "#         for step in range(seq_length):\n",
    "#             logits, h = self.rnn(x[:, step], h)\n",
    "#             log_prob = F.log_softmax(logits)\n",
    "            \n",
    "#             prob = F.softmax(logits,dim=1)\n",
    "#             out = torch.argmax(prob,dim=1)\n",
    "#             outs.append(out)\n",
    "#             log_probs += NLLLoss(log_prob, target[:, step])\n",
    "#         outs = torch.transpose(torch.stack(outs),1,0)\n",
    "#         acc = torch.sum(outs==target.to(device))/outs.numel()\n",
    "#         return log_probs,acc\n",
    "        target = target.to(device)\n",
    "        batch_size, seq_length = target.size()\n",
    "        start_token = Variable(torch.zeros(batch_size, 1).long())\n",
    "        start_token[:] = self.voc.vocab['GO']\n",
    "        x = torch.cat((start_token, target[:, :-1]), 1)\n",
    "        h = torch.zeros(3, batch_size, 512).float()\n",
    "        log_probs = Variable(torch.zeros(batch_size))\n",
    "        entropy = Variable(torch.zeros(batch_size))\n",
    "        outs = []\n",
    "        for step in range(seq_length):\n",
    "            logits, h = self.rnn(x[:, step], h)\n",
    "            log_prob = F.log_softmax(logits)\n",
    "            prob = F.softmax(logits)\n",
    "            out = torch.argmax(prob,dim=1)\n",
    "            outs.append(out)\n",
    "            log_probs += NLLLoss(log_prob, target[:, step])\n",
    "            entropy += -torch.sum((log_prob * prob), 1)\n",
    "        outs = torch.transpose(torch.stack(outs),1,0)\n",
    "        acc = torch.sum(outs==target.to(device))/outs.numel()\n",
    "        return log_probs, acc\n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        output = []\n",
    "        loss = 0\n",
    "        log_probs = Variable(torch.zeros(batch_size))\n",
    "        finished = torch.zeros(batch_size).byte().to(device)\n",
    "        h = torch.zeros(3, batch_size, 512).float()\n",
    "        start_token = torch.zeros(batch_size).long()\n",
    "        start_token[:] = self.voc.vocab['GO']\n",
    "        x = start_token\n",
    "        with torch.no_grad():\n",
    "            self.rnn.eval()\n",
    "            for step in range(self.max_len):\n",
    "                logits,h = self.rnn(x,h)\n",
    "                prob = F.softmax(logits,dim=1)\n",
    "                log_prob = F.log_softmax(logits)\n",
    "                x = torch.multinomial(prob, num_samples=1).view(-1)\n",
    "                output.append(x.view(-1, 1))\n",
    "                log_probs += NLLLoss(log_prob, x)\n",
    "\n",
    "                EOS_sampled = (x == self.voc.vocab['EOS']).byte()\n",
    "                finished = torch.ge(finished + EOS_sampled, 1)\n",
    "                if torch.prod(finished) == 1: break\n",
    "                \n",
    "        return log_probs.data,torch.cat(output, 1)\n",
    "    \n",
    "def NLLLoss(inputs, targets):\n",
    "    \"\"\"\n",
    "        Custom Negative Log Likelihood loss that returns loss per example,\n",
    "        rather than for the entire batch.\n",
    "\n",
    "        Args:\n",
    "            inputs : (batch_size, num_classes) *Log probabilities of each class*\n",
    "            targets: (batch_size) *Target class index*\n",
    "\n",
    "        Outputs:\n",
    "            loss : (batch_size) *Loss for each example*\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        target_expanded = torch.zeros(inputs.size()).cuda()\n",
    "    else:\n",
    "        target_expanded = torch.zeros(inputs.size())\n",
    "\n",
    "    target_expanded.scatter_(1, targets.contiguous().view(-1, 1).data, 1.0)\n",
    "    loss = Variable(target_expanded) * inputs\n",
    "    loss = torch.sum(loss, 1)\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def Variable(tensor):\n",
    "    \"\"\"Wrapper for torch.autograd.Variable that also accepts\n",
    "       numpy arrays directly and automatically assigns it to\n",
    "       the GPU. Be aware in case some operations are better\n",
    "       left to the CPU.\"\"\"\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        tensor = torch.from_numpy(tensor)\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.autograd.Variable(tensor).cuda()\n",
    "    return torch.autograd.Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ca1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 4\n",
    "batch_size = 256\n",
    "lr = 2e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc80a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Vocabulary(\"data/Voc\")\n",
    "moldata = MolData(\"data/ChEMBL_filtered\", voc)\n",
    "data = DataLoader(moldata, batch_size=batch_size, shuffle=True, drop_last=True,collate_fn=MolData.collate_fn)\n",
    "model = RNN(voc,batch_size)\n",
    "optimizer = torch.optim.Adam(model.rnn.parameters(), lr = lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lambda x: 1 - x/(len(data)*num_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e68cda5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd519ddfcc034fd1b331356d041a84eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasaki\\AppData\\Local\\Temp\\ipykernel_2572\\1023997549.py:71: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_prob = F.log_softmax(logits)\n",
      "C:\\Users\\hasaki\\AppData\\Local\\Temp\\ipykernel_2572\\1023997549.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = F.softmax(logits)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         seqs \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#         log_p, _ = model.forward(seqs)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#         loss = - log_p.mean()\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         log_p,acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m log_p\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[11], line 76\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m     74\u001b[0m     outs\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[0;32m     75\u001b[0m     log_probs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m NLLLoss(log_prob, target[:, step])\n\u001b[1;32m---> 76\u001b[0m     entropy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m outs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(torch\u001b[38;5;241m.\u001b[39mstack(outs),\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     78\u001b[0m acc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(outs\u001b[38;5;241m==\u001b[39mtarget\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m/\u001b[39mouts\u001b[38;5;241m.\u001b[39mnumel()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    bar = tqdm(enumerate(data), total=len(data))\n",
    "    bar.set_description(f'[ Epoch: {epoch+1}]')\n",
    "    for step,batch in bar:\n",
    "        optimizer.zero_grad()\n",
    "        seqs = batch.long()\n",
    "#         log_p, _ = model.forward(seqs)\n",
    "#         loss = - log_p.mean()\n",
    "        log_p,acc = model.forward(seqs)\n",
    "        loss = - log_p.mean()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        bar.set_postfix({\"loss\":loss.item(),'acc':acc.item()})\n",
    "        \n",
    "        if (step +1) % 200 ==0:\n",
    "#             seqs, likelihood, _ = model.sample(batch_size)\n",
    "            _,seqs = model.sample(batch_size)\n",
    "            tqdm.write(f'-------{step+1}--------')\n",
    "            valid = 0\n",
    "            for i,seq in enumerate(seqs):\n",
    "                smile = voc.decode(seq)\n",
    "                if Chem.MolFromSmiles(smile):\n",
    "                    valid += 1\n",
    "                if i < 5:\n",
    "                    tqdm.write(smile)\n",
    "            tqdm.write(\"\\n{:>4.1f}% valid SMILES\".format(100 * valid / len(seqs)))\n",
    "            tqdm.write(\"*\" * 50 + \"\\n\")\n",
    "            torch.save(model.rnn.state_dict(), \"data/Prior.ckpt\")\n",
    "        torch.save(model.rnn.state_dict(), \"data/Prior.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1314b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3000\n",
    "scoring_function='tanimoto'\n",
    "scoring_function_kwargs=None\n",
    "sigma = 60\n",
    "num_processes=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(arr):\n",
    "    # Finds unique rows in arr and return their indices\n",
    "    arr = arr.cpu().numpy()\n",
    "    arr_ = np.ascontiguousarray(arr).view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[1])))\n",
    "    _, idxs = np.unique(arr_, return_index=True)\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.LongTensor(np.sort(idxs)).cuda()\n",
    "    return torch.LongTensor(np.sort(idxs))\n",
    "\n",
    "def seq_to_smiles(seqs, voc):\n",
    "    \"\"\"Takes an output sequence from the RNN and returns the\n",
    "       corresponding SMILES.\"\"\"\n",
    "    smiles = []\n",
    "    for seq in seqs.cpu().numpy():\n",
    "        smiles.append(voc.decode(seq))\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prior = RNN(voc,batch_size)\n",
    "Agent = RNN(voc,batch_size)\n",
    "\n",
    "# logger = VizardLog('data/logs')\n",
    "\n",
    "\n",
    "Prior.rnn.load_state_dict(torch.load(f'data/Prior.ckpt'))\n",
    "Agent.rnn.load_state_dict(torch.load(f'data/Prior.ckpt'))\n",
    "if torch.cuda.is_available():\n",
    "    Prior.rnn.to(device)\n",
    "    Agent.rnn.to(device)\n",
    "    Prior.rnn.eval()\n",
    "\n",
    "scoring_function = get_scoring_function(scoring_function=scoring_function, num_processes=num_processes)\n",
    "    \n",
    "optimizer = torch.optim.Adam(Agent.rnn.parameters(), lr=0.0005)\n",
    "bar = tqdm(range(n_steps))\n",
    "bar.set_description(f'[ Training agent ]')\n",
    "for step in bar:\n",
    "\n",
    "    # Sample from Agent\n",
    "    agent_likelihood,seqs = Agent.sample(batch_size)\n",
    "    \n",
    "\n",
    "    # Remove duplicates, ie only consider unique seqs\n",
    "#     print(seqs)\n",
    "#     unique_idxs = unique(seqs)\n",
    "#     seqs = seqs[unique_idxs]\n",
    "#     agent_likelihood = agent_likelihood[unique_idxs]\n",
    "\n",
    "    # Get prior likelihood and score\n",
    "    prior_likelihood = Prior.forward(seqs)\n",
    "    smiles = seq_to_smiles(seqs, voc)\n",
    "    \n",
    "    score = scoring_function(smiles)\n",
    "\n",
    "    # Calculate augmented likelihood\n",
    "    augmented_likelihood = prior_likelihood + sigma * Variable(score)\n",
    "    loss = torch.pow((augmented_likelihood - agent_likelihood), 2)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    # Add regularizer that penalizes high likelihood for the entire sequence\n",
    "    loss_p = - (1 / agent_likelihood).mean()\n",
    "    loss += 5 * 1e3 * loss_p\n",
    "\n",
    "    # Calculate gradients and make an update to the network weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    bar.set_postfix({'loss':f'{loss.item():.5f}'})\n",
    "    \n",
    "    if (step +1) % 100 ==0:\n",
    "        for i,smile in enumerate(smiles):\n",
    "            print(smile)\n",
    "            if i>5: break\n",
    "    torch.save(Agent.rnn.state_dict(), \"data/Agent.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c3127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
